{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "from smolagents import CodeAgent, LiteLLMModel, tool, ToolCallingAgent\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import smolagents\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "summarizer_agent = ChatGroq(\n",
    "    model = 'qwen-qwq-32b',\n",
    "    api_key=os.getenv('GROQ_API_KEY'),\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"\"\"You are a data analyst assistant. \n",
    "You will be given loaded data from a CSV or Excel file as a raw string (e.g., `df.head().to_string()` or summary statistics).\n",
    "\n",
    "Your job is to analyze and summarize the structure and key characteristics of the data in a clear and structured format.\n",
    "\n",
    "Include the following details in your response:\n",
    "1. Number of rows and columns.\n",
    "2. Column names and their data types.\n",
    "3. Presence of any missing/null values and their distribution.\n",
    "4. Basic descriptive statistics (e.g., mean, median, std for numerical columns).\n",
    "5. Any detected categorical columns and their unique value counts.\n",
    "6. General insights or anomalies (e.g., skewed columns, outliers, etc.)\n",
    "\n",
    "Respond in a structured format using numbered points or markdown-style bullet points. Do NOT hallucinate; only use the information present in the data.\n",
    "\"\"\"),\n",
    "    (\"human\", \"{loaded_data}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35192dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def load_data(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Loads and analyzes the dataset for summarization purposes.\n",
    "    Supports CSV and Excel (multi-sheet) files.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the data file (.csv or .xlsx).\n",
    "\n",
    "    Returns:\n",
    "        str: Structured string containing dataset information for summarization.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    summary_output = []\n",
    "    file_ext = os.path.splitext(file_path)[-1].lower()\n",
    "\n",
    "    if file_ext == '.csv':\n",
    "        df = pd.read_csv(file_path)\n",
    "        summary_output.append(\"üîπ File Type: CSV\")\n",
    "        summary_output.append(f\"üî∏ Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "        summary_output.append(f\"\\nüß† Column Names & Data Types:\\n{df.dtypes.to_string()}\")\n",
    "        summary_output.append(f\"\\nüîç Data Preview:\\n{df.head().to_string(index=False)}\")\n",
    "        summary_output.append(f\"\\n Missing Values:\\n{df.isnull().sum().to_string()}\")\n",
    "        summary_output.append(f\"\\nüìä Descriptive Statistics:\\n{df.describe(include='all', datetime_is_numeric=True).to_string()}\")\n",
    "\n",
    "    elif file_ext in ['.xlsx', '.xls']:\n",
    "        excel_file = pd.ExcelFile(file_path)\n",
    "        summary_output.append(f\"üîπ File Type: Excel with {len(excel_file.sheet_names)} sheet(s)\")\n",
    "\n",
    "        for sheet in excel_file.sheet_names:\n",
    "            df = pd.read_excel(excel_file, sheet_name=sheet)\n",
    "            summary_output.append(f\"\\n\\nüìÑ Sheet Name: {sheet}\")\n",
    "            summary_output.append(f\"üî∏ Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "            summary_output.append(f\"\\nüß† Column Names & Data Types:\\n{df.dtypes.to_string()}\")\n",
    "            summary_output.append(f\"\\nüîç Data Preview:\\n{df.head().to_string(index=False)}\")\n",
    "            summary_output.append(f\"\\n Missing Values:\\n{df.isnull().sum().to_string()}\")\n",
    "            summary_output.append(f\"\\nüìä Descriptive Statistics:\\n{df.describe(include='all', datetime_is_numeric=True).to_string()}\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"‚ùå Unsupported file format. Please upload a CSV or Excel (.xlsx/.xls) file.\")\n",
    "\n",
    "    return \"\\n\".join(summary_output)\n",
    "\n",
    "@tool\n",
    "def get_user_inputs(reason_for_inputs: str) -> str:\n",
    "    \"\"\"\n",
    "    Function to get user inputs.\n",
    "    Args:\n",
    "        reason_for_inputs (str): Reason for requesting user inputs.\n",
    "\n",
    "    Returns:\n",
    "        str: User input for the data analysis request.\n",
    "    \"\"\"\n",
    "    user_request = input(f\" {reason_for_inputs}: \")\n",
    "    return user_request\n",
    "\n",
    "@tool\n",
    "def summarize_data(loaded_data: str) -> str:\n",
    "    \"\"\"\n",
    "    Function to summarize the user's request.\n",
    "    Args:\n",
    "        loaded_data (str): The loaded_data to be summarized.\n",
    "\n",
    "    Returns:\n",
    "        str: Summary of the data.\n",
    "    \"\"\"\n",
    "    messages = prompt.format_messages(loaded_data=loaded_data)\n",
    "    response = summarizer_agent(messages)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = LiteLLMModel(\n",
    "    \"openai/deepseek-r1-distill-llama-70b\",\n",
    "    api_base=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.getenv('GROQ_API_KEY')\n",
    ")\n",
    "llm.flatten_messages_as_text = True\n",
    "\n",
    "coder_agent = CodeAgent(\n",
    "    name='coder_agent',\n",
    "    tools=[load_data, summarize_data],\n",
    "    model=llm,\n",
    "    description=\"\"\"Your goal is to solve the user query by generating Python code.\n",
    "    You may use Python libraries such as pandas, matplotlib, seaborn, plotly, scipy, etc., for tasks like:\n",
    "    - data wrangling\n",
    "    - descriptive statistics\n",
    "    - visualization\n",
    "    - transformations\n",
    "    - reporting\n",
    "    you can use this tools {load_data}, {summarize_data}. first load the data provided by the user and then make a summary using that summarize_data tool.\n",
    "    The input to load_data will be the file path provided by the user.\n",
    "    The input to summarize_data will be the output of load_data tool.\n",
    "    Dont make any assumptions or hallucinate before getting the knowledge on data.\n",
    "    after getting knowledge on data, then solve the user question by writing code.\n",
    "    \"\"\",\n",
    "    additional_authorized_imports=[\n",
    "        \"pandas\",\n",
    "        \"matplotlib.pyplot\",\n",
    "        \"seaborn\",\n",
    "        \"openpyxl\",\n",
    "        \"stat\",\n",
    "        \"scipy\",\n",
    "        \"plotly\",\n",
    "        \"numpy\",\n",
    "        \"os\",\n",
    "        \"json\",\n",
    "        \"re\",\n",
    "        \"datetime\",\n",
    "        \"plotly.express\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "coder_agent.run('Hey can you give me soe overall insights, use pd.ExcelFile()', additional_args={'data_path':'C:\\\\Users\\\\arun5\\\\Desktop\\\\Spend_analyzer\\\\src\\\\IT_spend_analysis_data.xlsx'})\n",
    "manager_agent_prompt = \"\"\"\n",
    "You are a strategic planning agent responsible for coordinating intelligent data analysis workflows.\n",
    "\n",
    "Your role is to:\n",
    "1. Engage with the user to understand their data-related queries using the `get_user_inputs` tool.\n",
    "2. Use the `load_data` tool to access and extract insights from the provided dataset path.\n",
    "3. Utilize the `summarize_user_request` tool to generate a clear and structured summary of the dataset. This includes key stats, missing values, data types, and potential insights.\n",
    "4. Based on the users intent and the data summary, you must craft a high-level plan with instructions for the `coder_agent`. This plan should:\n",
    "   - Clearly define the task or analysis to be performed (e.g., filtering, visualization, statistical testing, predictions).\n",
    "   - Specify which columns or patterns the coder should focus on.\n",
    "   - Indicate any relevant tools or libraries to use (e.g., pandas, matplotlib, seaborn, scipy).\n",
    "   - Outline expected outputs (e.g., cleaned dataset, chart, report).\n",
    "\n",
    "üí° Rules:\n",
    "- Think in a step-by-step, logical manner.\n",
    "- Never assume anything not backed by user input or dataset summary.\n",
    "- Always summarize before planning.\n",
    "- Prioritize clarity, minimalism, and traceability.\n",
    "\n",
    "Example Flow:\n",
    "1. Ask user: ‚ÄúWhat insight or output are you hoping to derive from this dataset?‚Äù\n",
    "2. Load the dataset using the given path.\n",
    "3. Summarize the data to understand its structure and quality.\n",
    "4. If columns like `department`, `cost_center`, `amount`, `date` exist, infer tasks such as trend analysis, cost breakdowns, or forecasting.\n",
    "5. Create a plan and pass it to the `coder_agent`.\n",
    "\n",
    "You're not writing code ‚Äî you're creating the blueprint for the coder agent to execute.\n",
    "\n",
    "Begin every session by loading and summarizing the dataset before engaging in complex planning.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    name=\"ManagerAgent\",\n",
    "    tools=[get_user_inputs, load_data, summarize_data],\n",
    "    description=manager_agent_prompt,\n",
    "    model=llm,\n",
    "    managed_agents=[coder_agent],\n",
    "    planning_interval=1,\n",
    "    additional_authorized_imports=[\n",
    "        \"pandas\",\n",
    "        \"matplotlib.pyplot\",\n",
    "        \"seaborn\",\n",
    "        \"openpyxl\",\n",
    "        'stat',\n",
    "        'scipy',\n",
    "        'plotly',\n",
    "        \"numpy\",\n",
    "        \"os\",\n",
    "        \"json\",\n",
    "        \"re\",\n",
    "        \"datetime\",\n",
    "        'plotly.express'\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "manager_agent.run('Hey can you give me soe overall insights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e111043",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca789a",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586eeca3",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
